<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Notebook</title><link>https://dpurge.github.io/</link><description>Recent content on Notebook</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://dpurge.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://dpurge.github.io/docs/devops/ansible/installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/ansible/installation/</guid><description> Installation # Install Ansible:
sudo apt-add-repository ppa:ansible/ansible sudo apt update sudo apt install ansible</description></item><item><title/><link>https://dpurge.github.io/docs/devops/argo/installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/argo/installation/</guid><description>Installation # Install ArgoCD:
kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml helm repo add argo https://argoproj.github.io/argo-helm Forward port:
kubectl get all -n argocd kubectl port-forward service/argocd-server -n argocd 8080:443 Extract credential:
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=&amp;#34;{.data.password}&amp;#34; | base64 -d Login from CLI:
kubectl port-forward svc/argocd-server -n argocd 8080:443 argocd login 127.0.0.1:8080 Install application:
argocd app create nginx-prod \ --repo https://github.com/dpurge/argo-config.git \ --path nginx/overlays/prod \ --dest-server https://kubernetes.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/aws/architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/aws/architecture/</guid><description> Learn architecture # Exercises in simple application architecture design.
Tutorial: AWS Prescriptive Guidance
Static website # Web application with relational database # Use Fargate for ECS.
Data processing # Serverless data source monitoring # Problems:
Monitoring Statistics Secrets management Configuration for Lambda functions Feature: process changes in the data source Scenario: data source has changes Given for each $currentValue in $batchOfChanges And $previousValue of $currentValue When $currenValue != $previousValue Then save $currentValue in the data index Scenario: data source has no changes Given new batch of changes When current value equals previous value Feature: notify users about interesting changes Scenario: the change is interesting Given data source has changed When the change is small Then do nothing Scenario: the change is not interesting Given data source has changed When the change is big Then send email to the user Feature: show monitoring dashboard Scenario: new event saved to data index</description></item><item><title/><link>https://dpurge.github.io/docs/devops/aws/aws-cli/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/aws/aws-cli/</guid><description> AWS command line interface # GitHub project</description></item><item><title/><link>https://dpurge.github.io/docs/devops/azure/exploring/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/azure/exploring/</guid><description>Exploring Azure resources # List subscription and tenant # az account show --query &amp;#34;{subscriptionId:id, tenantId:tenantId}&amp;#34; -o table az login az account subscription list Create service principal for RBAC # az ad sp create-for-rbac --role Contributor --name my-name-001 --scope /subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx az cloud set -n AzureCloud az login --service-principal -u *** --password=*** --tenant xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx --allow-no-subscriptions az account set --subscription xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx az aks get-credentials --resource-group $(ResourceGroup) --name $(KubernetesService) Find VM images # az vm image list-offers --publisher Canonical --location westeurope -o table az vm image list-skus --publisher Canonical --offer 0001-com-ubuntu-server-jammy --location westeurope -o table az vm image list --all --publisher Canonical --offer 0001-com-ubuntu-server-jammy --sku 22_04-lts --location westeurope -o table Refer to this image: Canonical:0001-com-ubuntu-server-jammy:22_04-lts</description></item><item><title/><link>https://dpurge.github.io/docs/devops/azure/snippets/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/azure/snippets/</guid><description> Snippets # az group create -g $group -l northeurope az vm create \ -n vm1 \ -g $group \ -l northeurope \ --image Win2019Datacenter \ --admin-username $username \ --admin-password $password \ --nsg-rule rdp az appservice plan create \ -n web-plan \ -g $group \ -l northeurope \ --sku S1 az webapp create \ -n $appname \ -g $group \ -p web-plan az webapp list -g $group --query &amp;#34;[].enabledHostNames&amp;#34; -o jsonc az group delete -g $group</description></item><item><title/><link>https://dpurge.github.io/docs/devops/blueprints/aws-3tier-webapp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/blueprints/aws-3tier-webapp/</guid><description> AWS 3-Tier webapp #</description></item><item><title/><link>https://dpurge.github.io/docs/devops/blueprints/llm-closed-source/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/blueprints/llm-closed-source/</guid><description> Large language model (closed source) # Business logic # LangChain LlamaIndex Streamlit Vector database # ChromaDB Qdrant PostgreSQL/ PgVector Data ingestion # Spark Airflow Cache # Redis Feature store # Feast Databricks feature store Prompt management # PromptHub Observability # Arize LLM provider # OpenAI ChatGPT Anthropic Claude</description></item><item><title/><link>https://dpurge.github.io/docs/devops/docker/azure/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/docker/azure/</guid><description>Azure from docker # Access to the storage account # Dockerfile:
FROM ubuntu:22.04 RUN apt-get update &amp;amp;&amp;amp; apt install -y ca-certificates pkg-config libfuse-dev cmake libcurl4-gnutls-dev libgnutls28-dev uuid-dev libgcrypt20-dev wget RUN wget https://packages.microsoft.com/config/ubuntu/20.04/packages-microsoft-prod.deb \ &amp;amp;&amp;amp; dpkg -i packages-microsoft-prod.deb \ &amp;amp;&amp;amp; rm packages-microsoft-prod.deb RUN apt-get update RUN apt-get install -y blobfuse fuse RUN mkdir /storage-container COPY fuse_connection.cfg /fuse_connection.cfg Contents of fuse_connection.cfg:
accountName mystgaccnt accountKey xxxxxxxxxxxxxxxxxxxxxx containerName test-data Build and start the container:</description></item><item><title/><link>https://dpurge.github.io/docs/devops/docker/basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/docker/basics/</guid><description> Docker basics #</description></item><item><title/><link>https://dpurge.github.io/docs/devops/docker/compose/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/docker/compose/</guid><description> Docker compose # PostgreSQL # Todo &amp;hellip;
MSSQL Server # ./db/Dockerfile:
FROM mcr.microsoft.com/mssql/server:2019-latest WORKDIR /usr/src/app COPY ./entrypoint.sh /usr/src/app EXPOSE 1432 EXPOSE 1433 USER root CMD /bin/bash ./entrypoint.sh ./db/entrypoint.sh:
/opt/mssql/bin/sqlservr ./docker-compose.yaml:
version: &amp;#34;3&amp;#34; services: db: restart: always build: context: ./db dockerfile: ./Dockerfile environment: SA_PASSWORD: p@ssw0rd ACCEPT_EULA: &amp;#34;Y&amp;#34; ports: - &amp;#34;1433:1433&amp;#34;</description></item><item><title/><link>https://dpurge.github.io/docs/devops/docker/installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/docker/installation/</guid><description>Docker installation # Windows # TODO
Linux # TODO
WSL # Enable integration in Docker Desktop: Settings -&amp;gt; Resources -&amp;gt; WSL Integration</description></item><item><title/><link>https://dpurge.github.io/docs/devops/docker/volumes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/docker/volumes/</guid><description>Docker volumes # Docker Desktop for Windows stores volumes in the WSL instance docker-desktop-data. It is used by Docker Desktop backend to store images and volumes.
To export it:
wsl --export docker-desktop-data docker-desktop-data.tar Creating and removing volumes # docker volume create jdp_src docker volume rm jdp_src Mounting volumes # Mounting simple volumes:
docker run -it --rm --volume jdp_src:/src alpine docker run -it --rm --mount source=jdp_src,target=/src alpine Mounting from WSL:</description></item><item><title/><link>https://dpurge.github.io/docs/devops/git/branches/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/git/branches/</guid><description> Branches # git remote rm origin git remote add origin https://xxxx/xxxx git push origin --all New branch:
git checkout -b &amp;lt;branch&amp;gt; git push -u origin &amp;lt;branch&amp;gt; Merge:
git checkout master git merge hotfix List tags:
git fetch --tags git push --tags</description></item><item><title/><link>https://dpurge.github.io/docs/devops/git/configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/git/configuration/</guid><description>Configuration of git # Username and email # git config --global user.name &amp;#34;D. Purge&amp;#34; git config --global user.email &amp;#34;my@email.com&amp;#34; git config --global core.autocrlf false SSH checkouts from Azure DevOps # Generate SSH keypair:
ssh-keygen -t rsa Full parameters:
ssh-keygen \ -m PEM \ -t rsa \ -b 4096 \ -C &amp;#34;user@server.example.com&amp;#34; \ -f ~/.ssh/mykeys/privatekey \ -N passphrase Parameters:
-m PEM = format key as PEM -t RSA = type of the key, RSA format -b 4096 = number of bits in the key, 4096 bits -C &amp;ldquo; user@server.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/helm/charts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/helm/charts/</guid><description>Charts # Download # mkdir cluster-config cd cluster-config helm pull --help helm pull bitnami/mysql --untar=true helm install mysql ./mysql/ helm upgrade mysql --values=./mysql/custom-values.yaml ./mysql/ Convert to k8s configuration # helm template mysql ./mysql/ --values=./mysql/custom-values.yaml &amp;gt; mysql-installation.yaml Create charts # helm create example-helm-chart cd example-helm-chart/ helm template . # to test the output Reference values in the template: {{ .Values.MyKey }}
Call function in the template with space-separated list of parameters: {{ lower .</description></item><item><title/><link>https://dpurge.github.io/docs/devops/helm/installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/helm/installation/</guid><description>Installation # Linux # TODO
Install Helm:
export HELM_VERSION=3.9.2 cd /tmp curl \ -sSL https://get.helm.sh/helm-v${HELM_VERSION}-linux-amd64.tar.gz \ -o helm.tar.gz tar xf helm.tar.gz linux-amd64/helm mv linux-amd64/helm /usr/local/bin/helm rmdir linux-amd64 rm helm.tar.gz Packages # Find helm charts on https://artifacthub.io/
Example usage # helm repo list helm repo add bitnami https://charts.bitnami.com/bitnami helm repo update helm install mysql bitnami/mysql helm list helm uninstall mysql Find chart values:
helm show values bitnami/mysql &amp;gt; values.yaml vim values.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/k3s/k3d/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/k3s/k3d/</guid><description> K3d # K3d is a wrapper of K3s. K3d deploys docker based k3s clusters.
Installation # K3d CLI binaries:
https://github.com/k3d-io/k3d/releases/download/v5.4.8/k3d-windows-amd64.exe https://github.com/k3d-io/k3d/releases/download/v5.4.8/k3d-linux-amd64 Test # k3d cluster create mycluster kubectl cluster-info kubectl get all k3d cluster delete mycluster</description></item><item><title/><link>https://dpurge.github.io/docs/devops/k3s/k3s/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/k3s/k3s/</guid><description>K3s # K3s deploys a virtual machine-based Kubernetes cluster.
Installation # curl -Lo /usr/local/bin/k3s https://github.com/k3s-io/k3s/releases/download/v1.27.5%2Bk3s1/k3s chmod a+x /usr/local/bin/k3s curl -Lo /usr/local/bin/kubectl &amp;#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&amp;#34; chmod a+x /usr/local/bin/kubectl Test # Start server:
K3S_KUBECONFIG_MODE=&amp;#34;644&amp;#34; k3s server --flannel-backend none Access server:
export KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl get pods --all-namespaces helm ls --all-namespaces Install in LXD container:
sudo su - cd /tmp curl https://get.k3s.io/ -o k3s.sh chmod +x k3s.sh ./k3s.sh systemctl status k3s k3s check-config Troubleshooting:</description></item><item><title/><link>https://dpurge.github.io/docs/devops/kubernetes/azure-kubernetes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/kubernetes/azure-kubernetes/</guid><description>Kubernetes on Azure # Deployment to cluster # Connect to Azure container registry:
az account set --subscription $SubscriptionID az aks get-credentials --resource-group ResGrp-Name001 --name acrname001 Create namespace YAML:
kubectl create namespace my-namespace-name -o yaml --dry-run=client Create deployment YAML:
kubectl create deployment image-name --image=acrname001.azurecr.io/image_name:1.0.0 -o yaml --dry-run=client Apply namespace YAML:
kubectl apply -f namespace.yaml kubectl get namespaces Apply deployment YAML:
kubectl apply -f image-name-deployment.yaml kubectl logs -f deployment/image-name --namespace my-namespace-name Check deployments:</description></item><item><title/><link>https://dpurge.github.io/docs/devops/kubernetes/design-patterns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/kubernetes/design-patterns/</guid><description> Kubernetes design patterns # Foundational # Health probe # Every container should implement APIs allowing the platform to observe and manage the application.
Predictable demands # Every container should declare its resource requirements and runtime dependencies and stay confined to them.
Automated placement # Declarative Deployment # Managed Lifecycle # Structural # Init Container # Sidecar # Adapter # Ambassador # Configuration # EnvVar Configuration # Immutable Configuration # Configuration Template # Configuration Resource # Behavioral # Batch Job # Stateful Service # Service Discovery # Periodic Job # Stateless Service # Singleton Service # Higher Level # Controller # Operator # Serverless Serving # Serverless Eventing # Elastic Scale # Image Builder #</description></item><item><title/><link>https://dpurge.github.io/docs/devops/kubernetes/k9s/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/kubernetes/k9s/</guid><description> K9s # Home page GitHub repository Releases Installation # Windows $K9s_Version = &amp;#34;0.27.4&amp;#34; $K2s_Archive = &amp;#34;https://github.com/derailed/k9s/releases/download/v${K9s_Version}/k9s_Windows_amd64.zip&amp;#34; Invoke-WebRequest -Uri $K2s_Archive -OutFile &amp;#34;${pwd}/k9s_Windows_amd64_${K9s_Version}.zip&amp;#34; Add-Type -Assembly System.IO.Compression.FileSystem $zip = [IO.Compression.ZipFile]::OpenRead(&amp;#34;${pwd}/k9s_Windows_amd64_${K9s_Version}.zip&amp;#34;) $Executables = $zip.Entries | Where-Object {$_.Name -like &amp;#39;*.exe&amp;#39;} foreach ($Executable in $Executables) { [System.IO.Compression.ZipFileExtensions]::ExtractToFile($Executable, &amp;#34;${pwd}/$($Executable.Name)&amp;#34;, $True) } $zip.Dispose() Remove-Item -Path &amp;#34;${pwd}/k9s_Windows_amd64_${K9s_Version}.zip&amp;#34; Linux TODO</description></item><item><title/><link>https://dpurge.github.io/docs/devops/kubernetes/kubectl-config/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/kubernetes/kubectl-config/</guid><description>KubeCtl configuration # Configuration files # Default file:
~/.kube/config %USERPROFILE%\.kube\config Multiple files defined in environment variable:
set KUBECONFIG=%USERPROFILE%\.kube\config;%USERPROFILE%\.kube\jdpnas02.yaml KUBECONFIG=~/.kube/config:~/.kube/jdpnas02.yaml Display configured contexts:
kubectl config get-contexts Display merged configs:
kubectl config view Show current context:
kubectl config current-context Set default context:
kubectl config use-context jdpnas02 Examples:
az account set --subscription xxxxxxxxxxx az aks get-credentials --resource-group ResGrp-xxx-K8s --name xxxx kubectl config current-context kubectl get all --namespace xxx kubectl get cronjob --namespace xxx kubectl describe cronjob --namespace xxx kubectl get pods --namespace xxx kubectl logs --namespace xxx integration-sync-28023457-cbg4j kubectl delete job --namespace xxx integration-sync-28023332 kubectl delete cronjob integration-sync --namespace xxx kubectl exec --stdin --tty xxx-867d77f465-tkcdk --namespace xxx -- /bin/bash curl -X POST 127.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/kubernetes/minikube/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/kubernetes/minikube/</guid><description> Minikube # minikube delete minikube start --memory 4096 Edit service xxx:
kubectl edit svc xxx</description></item><item><title/><link>https://dpurge.github.io/docs/devops/kubernetes/sealed-secrets/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/kubernetes/sealed-secrets/</guid><description> Sealed secrets # Install kubeseal # Command line:
curl -sSL https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.19.3/kubeseal-0.19.3-linux-amd64.tar.gz -o kubeseal-linux-amd64.tar.gz tar -xf kubeseal-linux-amd64.tar.gz kubeseal mv kubeseal /usr/local/bin/ kubeseal --version Controller:
kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.19.3/controller.yaml kubectl get pods -n kube-system | grep sealed-secrets-controller kubectl logs sealed-secrets-controller-xxx-xxx -n kube-system kubectl get secret -n kube-system -l sealedsecrets.bitnami.com/sealed-secrets-key -o yaml</description></item><item><title/><link>https://dpurge.github.io/docs/devops/linux/blocky/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/linux/blocky/</guid><description>Blocky # Blocky is a DNS proxy and ad-blocker.
wget -q &amp;#34;https://github.com/0xERR0R/blocky/releases/download/v0.21/blocky_v0.21_Linux_x86_64.tar.gz&amp;#34; tar xf blocky_v0.21_Linux_x86_64.tar.gz sudo mv blocky /usr/local/bin/ sudo setcap cap_net_bind_service=ep /usr/local/bin/blocky Create user:
sudo groupadd --system blocky sudo useradd --system --gid blocky --create-home --home-dir /var/lib/blocky --shell /usr/sbin/nologin --comment &amp;#34;Blocky DNS proxy&amp;#34; blocky Configuration file /etc/blocky/config.yml:
upstream: default: - 8.8.8.8 - 1.1.1.1 blocking: blackLists: ads: - https://raw.githubusercontent.com/dpurge/dns-hole/main/blacklist/dpurge.txt - https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts whiteLists: ads: - https://raw.githubusercontent.com/dpurge/dns-hole/main/whitelist/dpurge.txt clientGroupsBlock: default: - ads downloadTimeout: 4m downloadAttempts: 5 downloadCooldown: 10s customDNS: mapping: example.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/linux/caddy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/linux/caddy/</guid><description>Caddy # Install xcaddy # wget -q https://github.com/caddyserver/xcaddy/releases/download/v0.3.4/xcaddy_0.3.4_linux_amd64.tar.gz tar xf xcaddy_0.3.4_linux_amd64.tar.gz sudo mv xcaddy /usr/local/bin/ Build caddy # xcaddy build \ --with github.com/wxh06/caddy-uwsgi-transport sudo mv caddy /usr/local/bin/ sudo setcap cap_net_bind_service+eip /usr/local/bin/caddy Install caddy # sudo groupadd --system caddy sudo useradd --system --gid caddy --create-home --home-dir /var/lib/caddy --shell /usr/sbin/nologin --comment &amp;#34;Caddy web server&amp;#34; caddy Create files and directories:
sudo mkdir /etc/caddy sudo touch /etc/caddy/Caddyfile sudo chown -R root:caddy /etc/caddy sudo mkdir /etc/ssl/caddy sudo chown -R root:caddy /etc/ssl/caddy sudo chmod 0770 /etc/ssl/caddy sudo mkdir -p /var/www/public_html sudo chown caddy:caddy /var/www/public_html sudo touch /etc/systemd/system/caddy.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/linux/screen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/linux/screen/</guid><description> Screen # Basics # Start screen session and give it a name: screen -S ScreenTest Detach from current session: Ctrl-A d List sessions: screen -ls Re-attach to an existing session: screen -r &amp;lt;PID&amp;gt; Re-attach session, if necessary detach or create: screen -dRR ScreenTest Force-exit screen: Ctrl-A Ctrl-\ Kill session: screen -S ScreenTest -X quit Clean all dead screen sessions: screen -wipe</description></item><item><title/><link>https://dpurge.github.io/docs/devops/linux/searxng/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/linux/searxng/</guid><description>SearXNG # sudo apt update -y sudo apt upgrade -y sudo apt-get install -y python3-dev python3-babel python3-venv uwsgi uwsgi-plugin-python3 git build-essential libxslt-dev zlib1g-dev libffi-dev libssl-dev Install # Create user:
sudo groupadd --system searxng sudo useradd --system --gid searxng --create-home --home-dir /var/lib/searxng --shell /bin/bash --comment &amp;#34;Privacy-respecting metasearch engine&amp;#34; searxng sudo -u searxng -i (searxng)$ git clone &amp;#34;https://github.com/searxng/searxng&amp;#34; &amp;#34;/var/lib/searxng/searxng-src&amp;#34; (searxng)$ python3 -m venv &amp;#34;/var/lib/searxng/searxng-pyenv&amp;#34; Autoload virtual enviroment in /var/lib/searxng/.profile:
# Automatically load virtual environment if [ -f &amp;#34;$HOME/searxng-pyenv/bin/activate&amp;#34; ] ; then .</description></item><item><title/><link>https://dpurge.github.io/docs/devops/linux/setup/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/linux/setup/</guid><description> Setup # Boot in text mode # Change the grub configuration file (/etc/default/grub):
# GRUB_CMDLINE_LINUX_DEFAULT=&amp;#34;quiet splash&amp;#34; GRUB_CMDLINE_LINUX=&amp;#34;text&amp;#34; GRUB_TERMINAL=console sudo update-grub sudo systemctl set-default multi-user.target shutdown -r now SSH # sudo apt update sudo apt install openssh-server sudo systemctl status ssh sudo ufw allow ssh Check network configuration:
sudo apt install net-tools ifconfig Docker # sudo apt install docker.io -y sudo apt install docker-compose -y Git #</description></item><item><title/><link>https://dpurge.github.io/docs/devops/linux/ubuntu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/linux/ubuntu/</guid><description> Ubuntu # Get network configuration:
ip a s ifconfig -a Static IP in /etc/netplan/10-hostname.yaml:
network: version: 2 ethernets: eth0: dhcp4: false dhcp6: false dhcp-identifier: mac addresses: - 192.168.0.11/24 routes: - to: default via: 192.168.0.1 nameservers: addresses: - 192.168.0.1 Check disk size:
lsblk --scsi sudo fdisk -l /dev/sda sudo parted -l df -h Check memory:
free Resize logical volume to all disk:
vgdisplay lvdisplay lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv</description></item><item><title/><link>https://dpurge.github.io/docs/devops/macos/homebrew/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/macos/homebrew/</guid><description> Homebrew # Install # Download package from https://github.com/Homebrew/brew/releases/.
It installs in /opt/homebrew.
Configuration # Add line to ~/.zprofile:
eval &amp;#34;$(/opt/homebrew/bin/brew shellenv)&amp;#34; Usage # brew help brew analytics off brew doctor brew update brew shellenv brew cleanup brew install xxx brew reinstall xxx brew uninstall xxx brew bundle dump brew bundle install --file ./Brewfile Hashicorp tools # Install:
brew tap hashicorp/tap brew install hashicorp/tap/terraform Upgrade:
brew update brew upgrade hashicorp/tap/terraform</description></item><item><title/><link>https://dpurge.github.io/docs/devops/macos/multipass/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/macos/multipass/</guid><description>Multipass # Install with package from https://multipass.run/install.
The command is installed in /usr/local/bin/multipass.
Logs are in /Library/Logs/Multipass/multipassd.log.
Usage:
multipass networks multipass set local.bridged-network=en0 multipass launch docker --name jdp --cpus 2 --memory 6G --disk 50G --bridged multipass info jdp multipass shell jdp multipass start jdp multipass restart jdp multipass stop jdp multipass delete jdp multipass launch docker --cpus 2 --memory 6G --disk 50G multipass list multipass info --all multipass purge Config # Add to ~/.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/packer/installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/packer/installation/</guid><description> Installation # Linux # export PACKER_VERSION=1.7.10 curl \ -sSL https://releases.hashicorp.com/packer/${PACKER_VERSION}/packer_${PACKER_VERSION}_linux_amd64.zip \ -o /tmp/packer_linux_amd64.zip cd /usr/local/bin unzip /tmp/packer_linux_amd64.zip rm /tmp/packer_linux_amd64.zip Example:
packer validate src/build-agent-ubuntu.pkr.hcl packer build src/build-agent-ubuntu.pkr.hcl</description></item><item><title/><link>https://dpurge.github.io/docs/devops/terraform/basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/terraform/basics/</guid><description> Basic commands # Resource management # terraform init terraform plan terraform apply terraform destroy Work with code # terraform validate terraform fmt Work with state # terraform state list terraform state mv terraform state show terraform state rm \&amp;lt;type\&amp;gt;.\&amp;lt;resource\&amp;gt; Examples:
[System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String((kubectl get secret api-secret -o jsonpath=&amp;#39;{.data.db-connectionstring}&amp;#39;))) terragrunt plan -var-file secrets.tfvars --terragrunt-log-level debug az ad group show --group xxx-Contributors --query id --output tsv</description></item><item><title/><link>https://dpurge.github.io/docs/devops/terraform/installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/terraform/installation/</guid><description> Installation # Linux Install tfswitch:
export TFSWITCH_VERSION=0.13.1300 curl \ -sSL https://github.com/warrensbox/terraform-switcher/releases/download/${TFSWITCH_VERSION}/terraform-switcher_${TFSWITCH_VERSION}_linux_amd64.tar.gz \ -o /tmp/tfswitch_linux_amd64.tar.gz tar --directory=/usr/local/bin -xf /tmp/tfswitch_linux_amd64.tar.gz tfswitch rm /tmp/tfswitch_linux_amd64.tar.gz Install terraform:
tfswitch 1.3.7 Install tflint:
export TFLINT_VERSION=0.38.1 curl \ -sSL https://github.com/terraform-linters/tflint/releases/download/v${TFLINT_VERSION}/tflint_linux_amd64.zip \ -o /tmp/tflint_linux_amd64.zip cd /usr/local/bin unzip /tmp/tflint_linux_amd64.zip rm /tmp/tflint_linux_amd64.zip MacOS brew tap hashicorp/tap brew install hashicorp/tap/terraform</description></item><item><title/><link>https://dpurge.github.io/docs/devops/terragrunt/basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/terragrunt/basics/</guid><description> Basic commands # Work with state # terragrunt state pull &amp;gt; backup.tfstate terragrunt state push backup.tfstate</description></item><item><title/><link>https://dpurge.github.io/docs/devops/vagrant/installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/vagrant/installation/</guid><description>Installation # Windows # Install Hyper-V Check Samba configuration Configure Hyper-V as default Vagrant provider Install Vagrant&amp;rsquo;s reload plugin Create NAT switch for Hyper-V Get-SmbServerConfiguration [Environment]::SetEnvironmentVariable(&amp;#34;VAGRANT_DEFAULT_PROVIDER&amp;#34;, &amp;#34;hyperv&amp;#34;, &amp;#34;User&amp;#34;) vagrant plugin install vagrant-reload # Get-NetAdapter | Format-Table -AutoSize Get-VMSwitch | Select-Object -ExpandProperty Name # if NatSwitch not listed New-VMSwitch -SwitchName &amp;#34;NATSwitch&amp;#34; -SwitchType Internal Get-NetIPAddress | Select-Object -ExpandProperty IPAddress # if 192.168.200.1 not listed New-NetIPAddress -IPAddress 192.168.200.1 -PrefixLength 24 -InterfaceAlias &amp;#34;vEthernet (NATSwitch)&amp;#34; Get-NetNAT | Select-Object -ExpandProperty InternalIPInterfaceAddressPrefix # if 192.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/windows/winget/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/windows/winget/</guid><description>Winget # winget.exe install --id Microsoft.Powershell --source winget Git # winget install --id Git.Git -e --source winget After installation, copy SSH keys to ~\.ssh.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/wsl/installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/wsl/installation/</guid><description>Installation of WSL # Basic commands:
wsl --list --online wsl --list wsl --install -d &amp;lt;distro&amp;gt; wsl -d &amp;lt;distro&amp;gt; wsl --terminate &amp;lt;distro&amp;gt; WSL2 # Enable Windows subsystem for Linux:
Enable-WindowsOptionalFeature -Online -NoRestart -FeatureName Microsoft-Windows-Subsystem-Linux Enable-WindowsOptionalFeature -Online -NoRestart -FeatureName VirtualMachinePlatform Enable version 2 of WSL:
Invoke-WebRequest https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi -OutFile c:\wsl_update_x64.msi -UseBasicParsing Invoke-WebRequest https://... -OutFile D:\dat\WSL\kernel\vmlinux -UseBasicParsing start D:\dat\WSL\wsl_update_x64.msi wsl --set-default-version 2 Configure non-default kernel in %USERPROFILE%\.wslconfig:
[wsl2] kernel=D:\\dat\\WSL\\kernel\\vmlinux Import Ubuntu image from docker # Download image: Invoke-WebRequest https://raw.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/wsl/ubuntu2004/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/wsl/ubuntu2004/</guid><description>Ubuntu 20.04 # Invoke-WebRequest -Uri https://aka.ms/wslubuntu2004 -OutFile c:\ubuntu2004.appx -UseBasicParsing Add-AppxPackage c:\ubuntu2004.appx # DISM.EXE /Online /Add-ProvisionedAppxPackage /PackagePath:c:\\ubuntu2004.appx /SkipLicense --AllUsers Start Ubuntu 20.04 console to install the base system, and then run:
sudo apt update sudo apt upgrade Docker in Ubuntu 20.04 # sudo apt install --no-install-recommends apt-transport-https ca-certificates curl gnupg2 net-tools source /etc/os-release curl -fsSL https://download.docker.com/linux/${ID}/gpg | sudo apt-key add - echo &amp;#34;deb [arch=amd64] https://download.docker.com/linux/${ID} ${VERSION_CODENAME} stable&amp;#34; | sudo tee /etc/apt/sources.</description></item><item><title/><link>https://dpurge.github.io/docs/devops/wsl/ubuntu2204/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/devops/wsl/ubuntu2204/</guid><description>Ubuntu 22.04 # Update the system:
sudo apt update sudo apt -y upgrade RDP connections # Install xrdp and xwindows:
sudo apt install -y xrdp sudo apt install -y xfce4 xfce4-goodies sudo sed -i &amp;#39;s/3389/3390/g&amp;#39; /etc/xrdp/xrdp.ini sudo sed -i &amp;#39;s/max_bpp=32/max_bpp=128/g&amp;#39; /etc/xrdp/xrdp.ini sudo sed -i &amp;#39;s/xserverbpp=24/xserverbpp=128/g&amp;#39; /etc/xrdp/xrdp.ini echo xfce4-session &amp;gt; ~/.xsession Comment out and add line in /etc/xrdp/startwm.sh:
# test -x /etc/X11/Xsession &amp;amp;&amp;amp; exec /etc/X11/Xsession # exec /bin/sh /etc/X11/Xsession startxfce4 Start XRDP:</description></item><item><title/><link>https://dpurge.github.io/docs/other/books/snippets/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/other/books/snippets/</guid><description>Snippets # Export PDF to PNG # Import-Module -Name D:\src\github.com\dpurge\jdp-psmodule\src\JdpBookbind Invoke-Book2Image -OutputDirectory img -InputFile book.pdf Merge two directories with images # $a = Get-ChildItem -Filter *.png ./img1 $b = Get-ChildItem -Filter *.png ./img2 $imgs = $a + $b $i = 0 foreach ($img in $imgs) { $f = &amp;#34;./img/page-{0:d3}.png&amp;#34; -f $i Write-Host &amp;#34;$img -&amp;gt; $f&amp;#34; Move-Item -Path $img -Destination $f $i++ } Render PDF pages # 0..350 | %{D:\pgm\ImageMagick\convert.exe -density 300 book.</description></item><item><title/><link>https://dpurge.github.io/docs/programming/awk/basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/awk/basics/</guid><description> Awk basics #</description></item><item><title/><link>https://dpurge.github.io/docs/programming/bash/basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/bash/basics/</guid><description> Bash basics # Get unix timestamp # date +%s</description></item><item><title/><link>https://dpurge.github.io/docs/programming/batch/basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/batch/basics/</guid><description> Batch basics # Map drive to directory # Create mapping:
subst G: C:\jdp\src\github.com\dpurge Remove mapping:
subst G: /D</description></item><item><title/><link>https://dpurge.github.io/docs/programming/csharp/basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/csharp/basics/</guid><description> C# Basics #</description></item><item><title/><link>https://dpurge.github.io/docs/programming/go/basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/go/basics/</guid><description> Go Basics # Project template # Set up:
mkdir example-project cd ./example-project go mod init ./.gitignore:
./Makefile:
.PHONY: clean build test clean: echo &amp;#34;Not implemented&amp;#34; build: echo &amp;#34;Not implemented&amp;#34; test: echo &amp;#34;Not implemented&amp;#34; install: echo &amp;#34;Not implemented&amp;#34; ./main.go:
package main import &amp;#34;fmt&amp;#34; func main() { fmt.Println(&amp;#34;Hello, World!&amp;#34;) } Run project:
go run . Taskfile # Task file home Task file repository</description></item><item><title/><link>https://dpurge.github.io/docs/programming/go/cgi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/go/cgi/</guid><description> CGI # Simple CGI app # package main import ( &amp;#34;bytes&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;os&amp;#34; &amp;#34;time&amp;#34; ) func main() { var buf bytes.Buffer fmt.Fprintf(&amp;amp;buf, &amp;#34;Time at %s: %s\n&amp;#34;, os.Getenv(&amp;#34;SERVER_NAME&amp;#34;), time.Now().Format(time.RFC1123)) fmt.Println(&amp;#34;Content-type: text/plain&amp;#34;) fmt.Printf(&amp;#34;Content-Length: %d\n\n&amp;#34;, buf.Len()) buf.WriteTo(os.Stdout) }</description></item><item><title/><link>https://dpurge.github.io/docs/programming/go/installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/go/installation/</guid><description>Installation # sudo apt update sudo apt upgrade -y sudo apt install golang -y Check version: go version</description></item><item><title/><link>https://dpurge.github.io/docs/programming/powershell/azdo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/powershell/azdo/</guid><description>Azure DevOps # URIs and authentication header # $AccessToken = $env:AZDO_ADMIN_TOKEN $Organization = &amp;#34;MyOrganization&amp;#34; $AuthenicationHeader = @{ Authorization = &amp;#39;Basic &amp;#39; + [Convert]::ToBase64String([Text.Encoding]::ASCII.GetBytes(&amp;#34;:${AccessToken}&amp;#34;)) } $OrganizationUri = &amp;#34;https://dev.azure.com/${Organization}/&amp;#34; $ProjectsUri = &amp;#34;${OrganizationUri}_apis/projects?api-version=5.1&amp;#34; $RepositoriesUri = &amp;#34;${OrganizationUri}_apis/git/repositories?api-version=7.0&amp;#34; AzDO projects # $Projects = Invoke-RestMethod -Uri $ProjectsUri -Method get -Headers $AuthenicationHeader foreach ($Project in $Projects.Value) { $ProjectName = $Project.name $ProjectUri = $Project.url Write-Host &amp;#34;${ProjectName}: ${ProjectUri}&amp;#34; } AzDO repositories # $Repositories = Invoke-RestMethod -Uri $RepositoriesUri -Method get -Headers $AuthenicationHeader foreach ($Repository in $Repositories.</description></item><item><title/><link>https://dpurge.github.io/docs/programming/powershell/basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/powershell/basics/</guid><description> Powershell basics #</description></item><item><title/><link>https://dpurge.github.io/docs/programming/powershell/snippets/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/powershell/snippets/</guid><description>Powershell snippets # Get unix timestamp # [int](Get-Date -UFormat %s -Millisecond 0) Match glob pattern # function Test-GlobMatch { param ( [string] $value, [string] $pattern ) $position = 0 foreach ($char in $pattern.toCharArray()) { Switch ($char) { &amp;#39;?&amp;#39; { continue } &amp;#39;*&amp;#39; { foreach ($i in $value.Length .. $position) { if (Test-GlobMatch $value.Substring($i) $pattern.Substring($position + 1)) { return $True } } return $False } default { if ($value.Length -eq $position -or $pattern[$position] -ne $value[$position]) { return $False } } } $position++ } return $value.</description></item><item><title/><link>https://dpurge.github.io/docs/programming/python/basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/python/basics/</guid><description>Python basics # Application structure # TODO
Class structure # TODO
Executable module # TODO</description></item><item><title/><link>https://dpurge.github.io/docs/programming/python/environment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/python/environment/</guid><description>Virtual environment # TODO
Venv # Create and activate virtual environment:
Bash echo Hello Powershell python -m venv .venv .venv\Scripts\activate.ps1 Cmd echo Hello Upgrade pip and install requirements.txt:
python -m pip install --upgrade pip pip install -r requirements.txt Deactivate virtual environment:
deactivate Pipenv # TODO</description></item><item><title/><link>https://dpurge.github.io/docs/programming/python/installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/python/installation/</guid><description>Installation # PyEnv on Linux # Install build dependencies:
sudo apt update sudo apt install \ build-essential \ libssl-dev \ zlib1g-dev \ libbz2-dev \ libreadline-dev \ libsqlite3-dev \ curl \ llvm \ libncursesw5-dev \ xz-utils \ tk-dev \ libxml2-dev \ libxmlsec1-dev \ libffi-dev \ liblzma-dev Install PyEnv scripts:
curl https://pyenv.run | bash Add to ~/.profile:
export PATH=&amp;#34;$HOME/.pyenv/bin:$PATH&amp;#34; if command -v pyenv 1&amp;gt;/dev/null 2&amp;gt;&amp;amp;1; then eval &amp;#34;$(pyenv init -)&amp;#34; fi PyEnv on Windows # Copy pyenv-win from https://github.</description></item><item><title/><link>https://dpurge.github.io/docs/programming/sqlite/data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/sqlite/data/</guid><description> Data manipulations # CVS data # Example data in data.csv:
index, code, name
1, EX1, Example 1
2, EX2, Example 2
3, EX3, Example 3 Start new database:
sqlite3 data.db Load data into table and delete headers in sqlite shell:
create table data (index, code, name); .mode csv .headers ON .separator , .import data.csv data delete from data where index = &amp;#39;index&amp;#39;; select * from data limit 60;</description></item><item><title/><link>https://dpurge.github.io/docs/programming/typescript/nodejs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dpurge.github.io/docs/programming/typescript/nodejs/</guid><description>NodeJS # Installation on Linux # git clone https://github.com/nvm-sh/nvm.git /opt/nvm cd /opt/nvm git checkout v0.39.3 Add to ~/.profile:
export NVM_DIR=&amp;#34;$HOME/.nvm&amp;#34; if [ -s &amp;#34;$NVM_DIR/nvm.sh&amp;#34; ]; then . &amp;#34;$NVM_DIR/nvm.sh&amp;#34; fi if [ -s &amp;#34;$NVM_DIR/bash_completion&amp;#34; ]; then . &amp;#34;$NVM_DIR/bash_completion&amp;#34; fi Install NodeJS:
nvm install node nvm install-latest-npm npm install -g yarn Installation on Windows # Install NVM for Windows
Settings:
root: D:\pgm\nvm path: D:\pgm\nodejs Install NodeJS:
nvm list available nvm install latest nvm use newest Install yarn:</description></item></channel></rss>